{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch, helpers, RequestError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_environment_vars() -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Loads environment variables from the parent directory .env file.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: Dictionary with Elasticsearch URL, username, and password.\n",
    "    \"\"\"\n",
    "    parent_dir: str = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "    dotenv_path: str = os.path.join(parent_dir, '.env')\n",
    "    load_dotenv(dotenv_path)\n",
    "    return {\n",
    "        \"ES_URL\": os.getenv('ELASTIC_URL'),\n",
    "        \"ES_User_Name\": os.getenv('ELASTIC_USERNAME'),\n",
    "        \"ES_Password\": os.getenv('ELASTIC_PASSWORD')\n",
    "    }\n",
    "\n",
    "env_vars: Dict[str, str] = load_environment_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create a global client connection to Elasticsearch\n",
    "es_client: Elasticsearch = Elasticsearch(\n",
    "    env_vars[\"ES_URL\"], \n",
    "    basic_auth=(env_vars[\"ES_User_Name\"], env_vars[\"ES_Password\"]),\n",
    "    verify_certs=False,\n",
    "    request_timeout=10000\n",
    ")\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_format_dates(csv_path: str, date_columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file, converts specified date columns from formats like '10-Mar-23'\n",
    "    to ISO 8601 (YYYY-MM-DDTHH:mm:ss) and fills missing values with 'N/A'.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        date_columns (List[str]): List of column names containing date values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with date columns formatted to ISO 8601.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df: pd.DataFrame = pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading CSV file: {e}\")\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', infer_datetime_format=True)\n",
    "        df[col] = df[col].dt.strftime(\"%Y-%m-%dT%H:%M:%S\").fillna(\"N/A\")\n",
    "    return df.fillna(\"N/A\")\n",
    "\n",
    "csv_file: str = \"elastic_data/employee_data.csv\"  \n",
    "date_cols: List[str] = [\"StartDate\", \"ExitDate\", \"DOB\"]\n",
    "df_formatted: pd.DataFrame = read_and_format_dates(csv_file, date_cols)\n",
    "df_formatted.to_csv(\"employees_formatted.csv\", index=False)\n",
    "df_formatted.to_json(\"employees_formatted.json\", orient=\"records\", lines=True)\n",
    "print(\"Date formatting completed and files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "index_mapping: Dict[str, Any] = {\n",
    "  \"settings\": {\n",
    "    \"number_of_replicas\": 0,\n",
    "    \"number_of_shards\": 1,\n",
    "    \"refresh_interval\": \"1m\"\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"EmpID\": {\"type\": \"integer\"},\n",
    "      \"FirstName\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}\n",
    "      },\n",
    "      \"LastName\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}\n",
    "      },\n",
    "      \"StartDate\": {\n",
    "        \"type\": \"date\",\n",
    "        \"format\": \"yyyy-MM-dd'T'HH:mm:ss||strict_date_time||epoch_millis\",\n",
    "        \"ignore_malformed\": True\n",
    "      },\n",
    "      \"ExitDate\": {\n",
    "        \"type\": \"date\",\n",
    "        \"format\": \"yyyy-MM-dd'T'HH:mm:ss||strict_date_time||epoch_millis\",\n",
    "        \"ignore_malformed\": True\n",
    "      },\n",
    "      \"Title\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}\n",
    "      },\n",
    "      \"Supervisor\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}\n",
    "      },\n",
    "      \"ADEmail\": {\"type\": \"keyword\"},\n",
    "      \"BusinessUnit\": {\"type\": \"keyword\"},\n",
    "      \"EmployeeStatus\": {\"type\": \"keyword\"},\n",
    "      \"EmployeeType\": {\"type\": \"keyword\"},\n",
    "      \"PayZone\": {\"type\": \"keyword\"},\n",
    "      \"EmployeeClassificationType\": {\"type\": \"keyword\"},\n",
    "      \"TerminationType\": {\"type\": \"keyword\"},\n",
    "      \"TerminationDescription\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}\n",
    "      },\n",
    "      \"DepartmentType\": {\"type\": \"keyword\"},\n",
    "      \"Division\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}\n",
    "      },\n",
    "      \"DOB\": {\n",
    "        \"type\": \"date\",\n",
    "        \"format\": \"yyyy-MM-dd'T'HH:mm:ss||strict_date_time||epoch_millis\",\n",
    "        \"ignore_malformed\": True\n",
    "      },\n",
    "      \"State\": {\"type\": \"keyword\"},\n",
    "      \"JobFunctionDescription\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}\n",
    "      },\n",
    "      \"GenderCode\": {\"type\": \"keyword\"},\n",
    "      \"LocationCode\": {\"type\": \"integer\"},\n",
    "      \"RaceDesc\": {\"type\": \"keyword\"},\n",
    "      \"MaritalDesc\": {\"type\": \"keyword\"},\n",
    "      \"Performance Score\": {\"type\": \"keyword\"},\n",
    "      \"Current Employee Rating\": {\"type\": \"integer\"}\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_index(index_name: str, mapping: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Creates an Elasticsearch index with the given mapping. Prints a message on success\n",
    "    or if the index already exists.\n",
    "\n",
    "    Args:\n",
    "        index_name (str): Name of the Elasticsearch index.\n",
    "        mapping (Dict[str, Any]): Mapping configuration for the index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        es_client.indices.create(index=index_name, body=mapping)\n",
    "        print(f\"Index '{index_name}' created successfully.\")\n",
    "    except RequestError as e:\n",
    "        if e.error == 'resource_already_exists_exception':\n",
    "            print(f\"Index '{index_name}' already exists.\")\n",
    "        else:\n",
    "            print(f\"An error occurred while creating index '{index_name}': {e}\")\n",
    "\n",
    "index_name: str = \"employee_data\"\n",
    "create_index(index_name, index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_json_file(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Loads JSON documents from a newline-delimited JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: List of JSON documents.\n",
    "    \"\"\"\n",
    "    documents: List[Dict[str, Any]] = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    documents.append(json.loads(line))\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading JSON file: {e}\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_documents(index_name: str, docs: List[Dict[str, Any]]) -> None:\n",
    "    \"\"\"\n",
    "    Bulk indexes JSON documents into the specified Elasticsearch index.\n",
    "\n",
    "    Args:\n",
    "        index_name (str): Target index name.\n",
    "        docs (List[Dict[str, Any]]): List of JSON documents.\n",
    "    \"\"\"\n",
    "    actions: List[Dict[str, Any]] = [{\"_index\": index_name, \"_source\": doc} for doc in docs]\n",
    "    try:\n",
    "        helpers.bulk(es_client, actions)\n",
    "        print(f\"Indexed {len(docs)} documents into index '{index_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error indexing documents: {e}\")\n",
    "\n",
    "json_file: str = \"employees_formatted.json\"\n",
    "documents: List[Dict[str, Any]] = load_json_file(json_file)\n",
    "index_documents(index_name, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
